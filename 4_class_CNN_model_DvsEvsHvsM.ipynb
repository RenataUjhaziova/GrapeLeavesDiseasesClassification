{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "#!rm -Rf HMP_Dataset\n#!git clone https://github.com/wchill/HMP_Dataset\n!rm -Rf dataset_DvsEvsHvsM", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "!git clone https://github.com/RenataUjhaziova/dataset_DvsEvsHvsM.git", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Cloning into 'dataset_DvsEvsHvsM'...\nremote: Enumerating objects: 4, done.\u001b[K\nremote: Counting objects: 100% (4/4), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 4372 (delta 0), reused 3 (delta 0), pack-reused 4368\u001b[K\nReceiving objects: 100% (4372/4372), 1.88 GiB | 42.14 MiB/s, done.\nResolving deltas: 100% (1/1), done.\nChecking out files: 100% (273/273), done.\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "!ls dataset_DvsEvsHvsM/test_set/dry/", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dry_01.JPG  dry_03.JPG\tdry_05.JPG  dry_07.JPG\tdry_09.JPG  dry_11.JPG\r\ndry_02.JPG  dry_04.JPG\tdry_06.JPG  dry_08.JPG\tdry_10.JPG  dry_12.JPG\r\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "#!git clone https://github.com/RenataUjhaziova/GrapeLeavesDiseasesClassification.git", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "fatal: destination path 'GrapeLeavesDiseasesClassification' already exists and is not an empty directory.\r\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "# Convolutional Neural Network for Hacatlon\n# Part 1 - Building the CNN\n\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "num_class = 4\n\n# Initialising the CNN\nclassifier = Sequential()\n\n#input_shape = (64, 64, 3)\ninput_shape = (128, 128, 3)\n\n# Step 1 - Convolution\nclassifier.add(Conv2D(filters = 32, kernel_size=(3,3), input_shape = input_shape, activation = 'relu'))\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolution layer\nclassifier.add(Conv2D(filters = 32, kernel_size=(3,3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(rate=0.20))\n\n'''\nclassifier.add(Conv2D(filters = 64, kernel_size=(3,3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(rate=0.20))\n'''\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(units = 128, activation = 'relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(Dropout(rate=0.5))\n\nclassifier.add(Dense(units = num_class, activation = 'softmax'))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "# Part 2 - Fitting the CNN to the images\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(shear_range = 0.2,\n                                   rescale = 1./255,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "# increase the target_size of the picture can help us get more info of our pixels patterns\n# increase this to 128 - use GPU\n#target_size = (64, 64)\ntarget_size = (128, 128)\ntraining_set = train_datagen.flow_from_directory('dataset_DvsEvsHvsM/training_set',\n                                                 target_size = target_size,\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical',\n                                                 shuffle=False)\n\ntest_set = test_datagen.flow_from_directory('dataset_DvsEvsHvsM/test_set',\n                                            target_size = target_size,\n                                            batch_size = 32,\n                                            class_mode = 'categorical', \n                                            shuffle=False)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Found 200 images belonging to 4 classes.\nFound 48 images belonging to 4 classes.\n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "print(test_set)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<keras.preprocessing.image.DirectoryIterator object at 0x7f218e812cf8>\n"
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "# checkpoint\nfilepath=\"GrapeLeavesDiseasesClassification/weights-improvement-DvsEvsHvsS-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nclassifier.fit_generator(training_set,\n                         steps_per_epoch=10,\n                         epochs = 1,\n                         validation_data = test_set,\n                         validation_steps = 48,\n                         callbacks=callbacks_list)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/1\n 9/10 [==========================>...] - ETA: 5s - loss: 1.7136 - acc: 0.2778 Epoch 00000: val_acc improved from -inf to 0.25000, saving model to GrapeLeavesDiseasesClassification/weights-improvement-DvsEvsHvsS-00-0.25.hdf5\n10/10 [==============================] - 230s - loss: 1.7207 - acc: 0.2783 - val_loss: 1.4799 - val_acc: 0.2500\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f218d3e6be0>"
                    }, 
                    "execution_count": 11, 
                    "metadata": {}
                }
            ], 
            "execution_count": 11
        }, 
        {
            "source": "classifier.save(filepath='GrapeLeavesDiseasesClassification/4_class_CNN_model_DvsEvsHvsS.h5')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 12
        }, 
        {
            "source": "classifier.save(filepath='https://github.com/RenataUjhaziova/GrapeLeavesDiseasesClassification/4_class_CNN_model_DvsEvsHvsS.h5')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "Unable to create file (Unable to open file: name = 'https://github.com/renataujhaziova/grapeleavesdiseasesclassification/4_class_cnn_model_dvsevshvss.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 242)", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-32-ac0d37a4950a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://github.com/RenataUjhaziova/GrapeLeavesDiseasesClassification/4_class_CNN_model_DvsEvsHvsS.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \"\"\"\n\u001b[1;32m   2505\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2506\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n", 
                        "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n", 
                        "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n", 
                        "\u001b[0;31mOSError\u001b[0m: Unable to create file (Unable to open file: name = 'https://github.com/renataujhaziova/grapeleavesdiseasesclassification/4_class_cnn_model_dvsevshvss.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 242)"
                    ], 
                    "ename": "OSError"
                }
            ], 
            "execution_count": 32
        }, 
        {
            "source": "!ls GrapeLeavesDiseasesClassification", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "4_class_CNN_model_DvsEvsHvsS.h5\r\nREADME.md\r\nweights-improvement-DvsEvsHvsS-00-0.25.hdf5\r\nweights-improvement-DvsEvsHvsS-00-0.31.hdf5\r\nweights-improvement-DvsEvsHvsS-00-0.42.hdf5\r\n"
                }
            ], 
            "execution_count": 13
        }, 
        {
            "source": "!pwd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/gpfs/fs01/user/s4c8-b01852febe9a7d-5b2f8c6fc8e5/notebook/work\r\n"
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "!cd GrapeLeavesDiseasesClassification", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 15
        }, 
        {
            "source": "!ls", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dataset_DvsEvsHvsM  GrapeLeavesDiseasesClassification\r\n"
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "# evaluate_generator uses both your test input and output. \n# It first predicts output using training input and then evaluates performance by comparing it against your test output. \n# So it gives out a measure of performance, i.e. accuracy in your case.\n\nscores = classifier.evaluate_generator(generator = test_set, steps = 10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 17
        }, 
        {
            "source": "print(\"Loss = \", scores[0], \", Accuracy = \", scores[1])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Loss =  1.47990981738 , Accuracy =  0.25\n"
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "validation_datagen = ImageDataGenerator(rescale = 1./255)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 19
        }, 
        {
            "source": "validation_set = validation_datagen.flow_from_directory('dataset_DvsEvsHvsM/validation_set',\n                                                   target_size = target_size,\n                                                   batch_size = 32,\n                                                   class_mode = 'categorical',\n                                                   shuffle=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Found 24 images belonging to 4 classes.\n"
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "#predict_generator takes your test data and gives you the output\nvalidation_set.reset()\npred=classifier.predict_generator(generator = validation_set,steps = 1, verbose=1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "1/1 [==============================] - 4s\n"
                }
            ], 
            "execution_count": 21
        }, 
        {
            "source": "print(len(pred))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "24\n"
                }
            ], 
            "execution_count": 22
        }, 
        {
            "source": "import numpy as np\npredicted_class_indices=np.argmax(pred,axis=1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 23
        }, 
        {
            "source": "print(predicted_class_indices)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
                }
            ], 
            "execution_count": 24
        }, 
        {
            "source": "labels_validation_set = (validation_set.class_indices)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 25
        }, 
        {
            "source": "labels_validation_set = dict((v,k) for k,v in labels_validation_set.items())", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 26
        }, 
        {
            "source": "predictions_validation_set = [labels_validation_set[k] for k in predicted_class_indices]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 27
        }, 
        {
            "source": "print(predictions_validation_set)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "['esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca', 'esca']\n"
                }
            ], 
            "execution_count": 28
        }, 
        {
            "source": "!ls", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dataset_DvsEvsHvsM  GrapeLeavesDiseasesClassification\r\n"
                }
            ], 
            "execution_count": 33
        }, 
        {
            "source": "!cd GrapeLeavesDiseasesClassification", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 37
        }, 
        {
            "source": "!cd GrapeLeavesDiseasesClassification", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 46
        }, 
        {
            "source": "!mv GrapeLeavesDiseasesClassification https://github.com/RenataUjhaziova/GrapeLeavesDiseasesClassification", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "mv: cannot move \u2018GrapeLeavesDiseasesClassification\u2019 to \u2018https://github.com/RenataUjhaziova/GrapeLeavesDiseasesClassification\u2019: No such file or directory\r\n"
                }
            ], 
            "execution_count": 53
        }, 
        {
            "source": "!git add .", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "fatal: Not a git repository (or any parent up to mount point /gpfs/global_fs01)\r\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
                }
            ], 
            "execution_count": 41
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}